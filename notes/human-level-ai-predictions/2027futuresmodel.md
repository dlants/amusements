https://www.aifuturesmodel.com/

Stage 1: Automating coding

Stage 1 predicts when coding in the AGI project will be fully automated. This stage centrally involves extrapolating the METR-HRS coding time horizon study.

Milestone endpoint: Automated Coder (AC). An AC can fully automate an AGI project's coding work, replacing the project’s entire software engineering staff.

The main drivers in Stage 1 are:

    Coding time horizon progression. We model how the coding time horizon trend progresses via parameters for (a) the effective compute increase currently required to double time horizon, (b) how this doubling requirement changes over time (i.e. whether time horizon growth is superexponential in log(effective compute)), and (c) the time horizon required for AC. In some simulations, we include a “gap” on top of reaching the time horizon requirement, in case doing well on the METR dataset doesn't immediately translate to doing well on real-world coding tasks.
    Partial automation of coding speeding up progress.
    Training compute growth slowing. We project that training compute growth will slow over time, due to limits on investment and the speed of building new fabs. This has a big impact in ~2035+ timelines.

Stage 2: Automating research taste

Besides coding, we track one other type of skill that is needed to automate AI software R&D: research taste. While automating coding makes an AI project faster at implementing experiments, automating research taste makes the project better at setting research directions, selecting experiments, and learning from experiments.

Stage 2 predicts how quickly we will go from an Automated Coder (AC) to a Superhuman AI researcher (SAR), an AI with research taste matching the top human researcher.

Milestone endpoint: Superhuman AI Researcher (SAR): A SAR can fully automate AI R&D.

The main drivers of how quickly Stage 2 goes is:

    How much automating coding speeds up AI R&D. This depends on a few factors, for example how severely the project gets bottlenecked on experiment compute.
    How good AIs' research taste is at the time AC is created. If AIs are better at research taste relative to coding, Stage 2 goes more quickly.
    How quickly AIs' research taste improves. For each 10x of effective compute, how much more value does one get per experiment?
