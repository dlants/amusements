---
title: AI & CS Education
draft: true
shortUrl: ai-cs-education
---

Recently, one of our interns expressed a concern I hear frequently from younger engineers: "I worry that my actual ability to write code will be degraded if I rely too much on AI coding assistants." This fear is understandable, but I believe it's ultimately misguided. In fact, I think we're witnessing a transformation that will make engineers more capable, not less.

## The Texting Parallel

This moment reminds me strikingly of when texting took off in the early 2000s. There was widespread panic that "textese" would destroy young people's writing abilities. Teachers and parents worried that shortcuts like "u" for "you" and "2" for "to" would leave an entire generation unable to write proper sentences.

What actually happened? The exact opposite. Because young people were reading and writing far more than previous generations—even if imperfectly—they became more articulate and better at expressing themselves. The sheer volume of practice outweighed any concerns about informal grammar.

I see the same pattern emerging with AI coding tools. Yes, you might rely on Copilot to generate boilerplate code or help you navigate unfamiliar libraries. But in doing so, you're reading, understanding, and working with vastly more code than you ever could before. This volume is transformative.

## From Isolation to Collaboration

Traditional computer science education has a fundamental flaw: students primarily work with code they've written themselves. It's all "green-field" development where you control every line. But that's not how real software engineering works. In the real world, you're constantly reading, understanding, and modifying code written by others.

AI tools accelerate this transition. Instead of spending hours deciphering documentation or Stack Overflow posts, you can quickly understand new libraries, explore different approaches, and see patterns across multiple codebases. You're not learning less—you're learning differently and more efficiently.

## The Trust-but-Verify Mindset

One intern wisely noted they're "constantly second-guessing and double-checking LLM references." This isn't a bug; it's a feature. Developing a healthy skepticism and verification habit is exactly the right approach.

The beauty of coding (unlike many other fields) is that we have objective truth: the code either compiles or it doesn't, the tests pass or they fail, the system works or it crashes. As long as you maintain strong fundamentals—edge case analysis, testing, verifying invariants—you'll catch any AI mistakes and learn from them.

## Reframing How We Learn

There's a pervasive belief in education that learning must be perfect and linear—that one misconception early on will topple everything built on top of it. But that's not how human learning actually works. Learning is messy, iterative, and full of corrections.

When an AI gives you slightly incorrect code, and you debug it, you often learn more than if you'd written it perfectly the first time. You develop debugging skills, deepen your understanding of why something works a certain way, and build intuition about common failure modes.

## The New Skill Set

Rather than degrading your abilities, AI tools demand new skills:

- **Prompt engineering**: How to effectively communicate with AI systems
- **Context management**: Understanding what information the AI needs to help you effectively
- **Problem decomposition**: Breaking complex tasks into AI-manageable chunks
- **Quality assessment**: Quickly evaluating whether generated code meets your standards
- **Integration thinking**: Understanding how AI-generated components fit into larger systems
These aren't replacements for fundamental programming skills—they're additions to your toolkit.

## Embracing the Volume Advantage

Before AI tools, even experienced developers might only deeply understand a handful of frameworks and libraries. Now, I find myself confidently working across multiple languages, frameworks, and paradigms in a single day. The acceleration in learning and productivity is remarkable.

Young engineers who embrace these tools aren't handicapping themselves—they're positioning themselves at the forefront of a new era in software development. The engineers who thrive will be those who can leverage AI to amplify their capabilities while maintaining strong fundamental skills.



I recommend [https://www.heinemann.com/cgimath/](https://www.heinemann.com/cgimath/) as an intro to the science of teaching & learning


(it's focused on early math education, but I think lays out the core principles of how humans acquire, retain, and generalize knowledge really well)


and I think CS follows similar patterns (concrete -> abstract, specific -> general, etc...)

## A Personal Note

To the interns and young engineers reading this: your concerns are valid and show good judgment. Questioning new tools and their impact is exactly the kind of critical thinking our field needs. But don't let fear hold you back from tools that can accelerate your growth.

Use AI assistants, but use them thoughtfully. Let them handle the boilerplate while you focus on architecture and edge cases. Let them help you explore new territories while you maintain ownership of the core logic. Most importantly, let them free you to tackle more ambitious projects than you ever could alone.

The future of software engineering isn't human versus AI—it's human with AI. And those who start building that partnership early will have a significant advantage.

---

*What are your thoughts on AI in software development? How do you balance leveraging AI tools with maintaining core skills? I'd love to hear your experiences in the comments.*
